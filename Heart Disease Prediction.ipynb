{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cbf5d47",
   "metadata": {},
   "source": [
    "# Capstone Project : Heart Disease Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f92f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16982dc5",
   "metadata": {},
   "source": [
    "### 1. Load the dataset and familiarize  with the features and their descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73215a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\CCI\\OneDrive\\Desktop\\BIA\\14. Capstone Project\\heart_disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db6a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an overview of the dataset\n",
    "print(\"\\nDataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ab438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Analysis of the dataset\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e734ff",
   "metadata": {},
   "source": [
    "##  Features and Their Descriptions\n",
    "   **Below is a detailed description of each feature in the dataset:**\n",
    "\n",
    " **1) Age** : The age of the patient in years.\n",
    "\n",
    "**2) Sex**: The gender of the patient.\n",
    "\n",
    "         1: Male\n",
    "         0: Female\n",
    "        \n",
    "**3) Chest pain type:** The type of chest pain experienced by the patient.\n",
    "\n",
    "        0: Typical angina\n",
    "        1: Atypical angina\n",
    "        2: Non-anginal pain\n",
    "        3: Asymptomatic\n",
    "        \n",
    "__4) Resting blood pressure__: The resting blood pressure (in mm Hg) of the patient.\n",
    "\n",
    "__5) Serum cholesterol levels__: The serum cholesterol level (in mg/dL) of the patient.\n",
    "\n",
    "__6) Fasting blood sugar__: Indicates if the patient's fasting blood sugar is greater than 120 mg/dL.\n",
    "\n",
    "       1: True (fasting blood sugar > 120 mg/dL)\n",
    "       0: False (fasting blood sugar ≤ 120 mg/dL)\n",
    "        \n",
    "__7) Resting electrocardiographic results__: Results of the resting electrocardiogram (ECG).\n",
    "\n",
    "        0: Normal\n",
    "        1: Having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "        2: Showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "        \n",
    "__8) Maximum heart rate achieved__: The maximum heart rate achieved during exercise.\n",
    "\n",
    "__9) Exercise-induced angina__: Indicates if the patient experiences angina induced by exercise.\n",
    "\n",
    "        1: Yes\n",
    "        0: No\n",
    "        \n",
    "__10) ST depression induced by exercise relative to rest__: The value of depression in the ST segment during exercise compared to rest.\n",
    "\n",
    "__11) Slope of the peak exercise ST segment__: The slope of the peak exercise ST segment.\n",
    "\n",
    "        0: Upsloping\n",
    "        1: Flat\n",
    "        2: Downsloping\n",
    "        \n",
    "__12) Number of major vessels colored by fluoroscopy__: The number of major vessels (ranging from 0 to 4) colored by fluoroscopy.\n",
    "\n",
    "__13) Thalassemia__: A blood disorder involving lower-than-normal amounts of an oxygen-carrying protein.\n",
    "\n",
    "        0: Normal\n",
    "        1: Fixed defect\n",
    "        2: Reversible defect\n",
    "        3: Not described\n",
    "        \n",
    "__14) Target variable__: Indicates the presence or absence of heart disease.\n",
    "\n",
    "        1: Presence of heart disease\n",
    "        0: Absence of heart disease\n",
    "        \n",
    "These descriptions provide a comprehensive understanding of each feature in the dataset, which is crucial for data exploration and preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d96b83",
   "metadata": {},
   "source": [
    "#### __Note:__ \n",
    "\n",
    ">**Even though some of our columns (like sex, cp, fbs, restecg, exang, slope, ca, thal, and target) have numbers in them, they actually represent categories or groups. For example, 'sex' might have numbers like 0 and 1 to represent male and female, but it's really about different groups. To understand and work with these columns correctly, we need to change their data type to \"text\" (also known as \"object\"). This will help us analyze and interpret them properly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of continuous features\n",
    "cont_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "# Determine which columns should be converted to object data type\n",
    "#Finds all columns not listed in cont_cols\n",
    "cate_cols = df.columns.difference(cont_cols)\n",
    "\n",
    "# Convert these columns to object data type\n",
    "df[cate_cols] = df[cate_cols].apply(lambda x: x.astype('object'))\n",
    "\n",
    "# Check the data types of all columns\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe83590",
   "metadata": {},
   "source": [
    "## 2. Summary Statistics for Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0734c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a7c4f3",
   "metadata": {},
   "source": [
    "__Numerical Variables Summary:__\n",
    "\n",
    " 1. The dataset covers a wide age range from 29 to 77 years, with a mean age of 54.43 years.\n",
    " 2. Resting blood pressure ranges from 94 to 200 mm Hg, with an average of 131.61 mm Hg.\n",
    " 3. Serum cholesterol levels exhibit significant variability, ranging from 126 to 564 mg/dL, with an average of 246.0 mg/dL.\n",
    " 4. Maximum heart rate achieved also shows variability, with values ranging from 71 to 202 bpm, and a mean of 149.11 bpm.\n",
    " 5. ST depression induced by exercise (oldpeak) ranges from 0.0 to 6.2, with an average of 1.07, indicating variability in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218404d2",
   "metadata": {},
   "source": [
    "## 3. Summary Statistics for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec21df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e956a9",
   "metadata": {},
   "source": [
    "#### Categorical Variables Summary \n",
    "\n",
    " 1. Sex: The majority of the dataset consists of males (1), representing about 69.56% of the population.\n",
    " 2. Chest Pain Type (cp): The most common chest pain type is 0, making up approximately 48.49% of the observations.\n",
    " 3. Fasting Blood Sugar (fbs): Most individuals do not have fasting blood sugar greater than 120 mg/dL, with 85.07% of the values being 0.\n",
    " 4. Resting Electrocardiographic Results (restecg): The most frequent resting ECG result is 1, accounting for roughly 50.05% of the cases.\n",
    " 5. Exercise Induced Angina (exang): A large portion of individuals do not experience exercise-induced angina, with 66.34% of the values being 0.\n",
    " 6. Slope of the Peak Exercise ST Segment (slope): The most common slope value is 1, which appears 47.02% of the time.\n",
    " 7. Number of Major Vessels Colored by Fluoroscopy (ca): Most individuals have 0 major vessels colored by fluoroscopy, comprising about 56.39% of the observations.\n",
    " 8. Thalassemia (thal): The most common thalassemia value is 2, representing 53.07% of the observations.\n",
    " 9. Target: There is a near-even split in the target variable, with a slight majority (51.32%) indicating the presence of heart disease (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84998157",
   "metadata": {},
   "source": [
    "## 4. Check for missing values and handle them appropriately (e.g., imputation or removal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7577c02a",
   "metadata": {},
   "source": [
    "#### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e7396",
   "metadata": {},
   "source": [
    "**Since our dataset doesn't have any missing values, we don’t need to perform imputation (filling in missing data) or removal (discarding incomplete data).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f42405",
   "metadata": {},
   "source": [
    "## 5. Removing Unnecessary Columns\n",
    "\n",
    "   >**Based on our analysis, all the features in the dataset seem important. None of the columns appear to be unnecessary or unimportant. Therefore, we will keep all the features to make sure we don't lose any valuable information, especially since the dataset is small.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee4544",
   "metadata": {},
   "source": [
    "## 6. EDA (Exploratory Data Analysis)\n",
    "\n",
    "   >**Perform exploratory data analysis (EDA) to understand the distribution of features, identify outliers, and visualize relationships between features and the target variable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb3a4b",
   "metadata": {},
   "source": [
    "### 6.1) Visualization For Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a38d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check age distribution in the dataset\n",
    "\n",
    "# Plot the distribution of the 'age' column\n",
    "plt.figure(figsize=(8, 6))  # Adjust the size as needed\n",
    "sns.histplot(df['age'], color='#0D0DF4', bins=10, kde=True)  # Use histplot with KDE\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Distribution of Age Variable', fontweight='bold')\n",
    "plt.xlabel('Age', fontweight='bold')\n",
    "plt.ylabel('Count', fontweight='bold')\n",
    "plt.grid(True)  # Add grid lines\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a31b8",
   "metadata": {},
   "source": [
    "### Summary :\n",
    "\n",
    "  1. The height of each bar shows how many people fall into that age range. The taller the bar, the more people there are in that age group.\n",
    "\n",
    " 2. Looking at the chart, you can see that one bar is clearly taller than the others. This is the most common age range, which we call the mode. In this case, it seems like there are more people in their 50s and 60s compared to other age groups.\n",
    "\n",
    "  3. As you move towards the right side of the chart (older ages), the bars generally get shorter. This suggests that there are fewer and fewer people as we go up in age. This pattern is called a positive skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edb1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the count distribution of the 'sex' column\n",
    "plt.figure(figsize=(8, 6))  # Adjust the size as needed\n",
    "sns.countplot(x='sex', data=df, palette='Set1')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Distribution of Sex Variable', fontweight='bold')\n",
    "plt.xlabel('Sex', fontweight='bold')\n",
    "plt.ylabel('Count', fontweight='bold')\n",
    "  # Add grid lines\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oldpeak - Density Plot\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.kdeplot(df['oldpeak'], shade=True, color='#154360')\n",
    "plt.title('Density Plot of ST Depression Induced by Exercise (Oldpeak)', fontsize=10, fontweight='bold')\n",
    "plt.xlabel('ST Depression (Oldpeak)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Density', fontsize=10, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfee535",
   "metadata": {},
   "source": [
    "### Summary :\n",
    "   >**The shape of the curve in the plot is important.  This particular density plot is bell-shaped, which is a normal distribution. This means that most people fall around an average amount of ST depression caused by exercise, with fewer people having very low or very high amounts.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a59116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the histogram\n",
    "sns.histplot(df['chol'], bins=20, kde=True, color='#154360')\n",
    "\n",
    "# Add a title and axis labels\n",
    "plt.title('Distribution of Serum Cholesterol Levels', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Serum Cholesterol (mg/dL)', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('Frequency', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Add grid lines for better readability\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add annotations for mean and median\n",
    "mean_chol = df['chol'].mean()\n",
    "median_chol = df['chol'].median()\n",
    "plt.axvline(mean_chol, color='red', linestyle='--', linewidth=1, label=f'Mean: {mean_chol:.2f}')\n",
    "plt.axvline(median_chol, color='green', linestyle='--', linewidth=1, label=f'Median: {median_chol:.2f}')\n",
    "\n",
    "# Customize the legend\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f4ff9",
   "metadata": {},
   "source": [
    "### Summary :\n",
    "   >1. The chart has bars of varying heights, which means the number of people with different cholesterol levels varies. There seems to be a peak around 200-250 mg/dL, which suggests this might be the most common cholesterol level in this dataset.\n",
    "   >2. We can also say that the chart is skewed to the right. This means there are more people with higher cholesterol levels (towards the right side of the chart) than there are people with lower cholesterol levels (towards the left side of the chart)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439d8426",
   "metadata": {},
   "source": [
    "## 6.2) Univariate Analysis: Histograms with KDE for numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6544421",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(cont_cols, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(df[col], kde=True, bins=10, color='darkblue')\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Univariate Analysis of Numerical Features', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93094c0",
   "metadata": {},
   "source": [
    "### Inference :\n",
    " 1. __Age__: Most people's ages are spread out, but many are in their late 50s. The average age is about 54 years, with most people being within 9 years of that age.\n",
    "\n",
    "2. __Resting Blood Pressure__: Most people have a resting blood pressure between 120 and 140 mm Hg. The average is about 132 mm Hg, with most people being within 18 mm Hg of that number.\n",
    "\n",
    "3. __Serum Cholesterol__: Cholesterol levels for most people are between 200 and 280 mg/dl. The average cholesterol level is around 246 mg/dl, with most people being within 52 mg/dl of that average.\n",
    "\n",
    "4. __Maximum Heart Rate Achieved__: During a stress test, most people reach a heart rate between 140 and 170 bpm. The average maximum heart rate is about 149 bpm, with most people being within 23 bpm of that number.\n",
    "\n",
    "5. __ST Depression Induced by Exercise__: Most people have values close to 0, meaning they didn't experience much ST depression during exercise. The average ST depression is about 1, with most people being within 1 of that average.\n",
    "\n",
    "__After looking at the histograms (which are like bar charts) of the continuous features and checking them against their descriptions, everything looks normal and as expected. There are no unusual or strange values in the continuous variables.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b1d87",
   "metadata": {},
   "source": [
    "## 6.3) Bivariate Analysis for Numerical Variables with Target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn style and font scale\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "# Define target variable\n",
    "target_variable = 'target'  # Replace 'target' with your actual target variable name\n",
    "\n",
    "# Create subplots for bivariate analysis\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, col in enumerate(cont_cols, start=1):\n",
    "    plt.subplot(3, 2, i)\n",
    "    sns.histplot(data=df, x=col, hue=target_variable, multiple='stack', kde=True, palette='Set1')\n",
    "    plt.title(f'{col.capitalize()} Distribution by {target_variable.capitalize()}', fontweight='bold')\n",
    "    plt.xlabel(col.capitalize(), fontweight='bold')\n",
    "    plt.ylabel('Frequency', fontweight='bold')\n",
    "    #plt.legend(title=target_variable.capitalize())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa0e7b",
   "metadata": {},
   "source": [
    "## Inference : \n",
    "\n",
    "1. __Age__: People with heart disease are, on average, a bit younger than those without it. Those without heart disease are usually older.\n",
    "\n",
    "2. __Resting Blood Pressure__: The blood pressure levels for both groups (with and without heart disease) look very similar, so it’s not very useful for telling the difference between the two groups.\n",
    "\n",
    "3. __Serum Cholesterol__: Cholesterol levels are also similar for both groups, but people with heart disease have a slightly lower average cholesterol level.\n",
    "\n",
    "4. __Maximum Heart Rate Achieved__: People with heart disease tend to reach a higher maximum heart rate during stress tests compared to those without heart disease.\n",
    "\n",
    "5. __ST Depression__: People with heart disease show much less ST depression during exercise. Their results are mostly close to zero, while those without heart disease show a wider range of results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3cf0c4",
   "metadata": {},
   "source": [
    "## 6.4) Visualization for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the countplot with hue specified\n",
    "plt.figure(figsize=(8, 6))  # Adjust the figure size as needed\n",
    "sns.countplot(x='target', hue='target', data=df, palette='Set1')\n",
    "\n",
    "plt.title('Distribution of Target Variable', fontweight='bold', fontsize=14)\n",
    "plt.xlabel('Target', fontweight='bold', fontsize=12)\n",
    "plt.ylabel('Count', fontweight='bold', fontsize=12)\n",
    "\n",
    "# Set legend outside the plot and adjust position\n",
    "plt.legend(labels=['Absence Of Disease', 'Presence Of Disease'], loc='upper center',)\n",
    "print(df['target'].value_counts())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbe94fd",
   "metadata": {},
   "source": [
    "###  Count of male and female with the presence and absence of disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_target_counts = df.groupby(['sex', 'target']).size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='sex', hue='target', data=df, palette='Set1')\n",
    "plt.title('Distribution of Sex over Target Variable', fontweight='bold')\n",
    "plt.xlabel('Sex', fontweight='bold')\n",
    "plt.ylabel('Count', fontweight='bold')\n",
    "plt.xticks([1,0], [\"Male\", \"Female\"])\n",
    "plt.legend(labels=['Absence Of Disease', 'Presence Of Disease'])\n",
    "print(sex_target_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values of cp\n",
    "cp_counts = df['cp'].value_counts()\n",
    "\n",
    "# Custom color palette\n",
    "# cp_type = [0: Typical angina, 1: Atypical angina, 2: Non-anginal pain, 3: Asymptomatic]\n",
    "custom_colors = ['#E59866', '#5DADE2', '#F1948A', '#ABEBC6']\n",
    "\n",
    "# Plotting the pie chart\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(cp_counts, labels=cp_counts.index, autopct='%1.1f%%', startangle=140, colors=custom_colors) #plt.cm.Set3.colors)\n",
    "plt.title('Distribution of Chest Pain Types (cp)', fontsize=14, fontweight='bold')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a7f8e",
   "metadata": {},
   "source": [
    "#### Inference : \n",
    "__Typical Angina (0)__: Sometimes the heart's door gets a little blocked, making it harder for blood to get in. This can cause a squeezing or tightness in your chest, like someone is gently hugging you too hard. It usually goes away with rest.\n",
    "\n",
    "__Atypical Angina (1)__: This is like typical angina, but the feeling might be different. It might be a pain in your arm, jaw, or back instead of your chest. It's important to tell an adult if you feel this kind of pain.\n",
    "\n",
    "__Non-Anginal Pain (2)__: Not all chest pain comes from the heart! Sometimes you might have a cough, heartburn, or a muscle pull that makes your chest hurt. This kind of pain usually feels different than angina and goes away on its own.\n",
    "\n",
    "__Asymptomatic (3)__: This is a big word that means \"no symptoms.\" Some people might have problems with their heart but not feel any pain at all. It's important for grown-ups to get checkups to make sure everything is working well, even if they don't feel sick."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feceba0e",
   "metadata": {},
   "source": [
    "## Show fasting blood sugar distribution according to sex variable\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbs_target_counts = df.groupby(['fbs', 'sex']).size().reset_index(name='count')\n",
    "# 1 true = above 120 mg/dl , 0 false = below 120 mg/dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='fbs', hue='sex', data=df, palette='Set1')\n",
    "plt.title('Distribution of FBS over Sex Variable', fontweight='bold')\n",
    "plt.xlabel('Fasting Blood Sugar(<= 120 mg/dl, > 120 mg/dl)', fontweight='bold')\n",
    "plt.ylabel('Count', fontweight='bold')\n",
    "plt.legend(labels=['Female','Male'])\n",
    "plt.xticks([0, 1], ['False', 'True'])\n",
    "print(fbs_target_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90df8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'target' from the list of categorical columns\n",
    "cate_cols = [col for col in cate_cols if col != 'target']\n",
    "cate_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6da4a8",
   "metadata": {},
   "source": [
    "## 6.5) Univariate Analysis of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a78ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 20))\n",
    "\n",
    "for i, col in enumerate(cate_cols, 1):\n",
    "    plt.subplot(4, 2, i)\n",
    "    ax = sns.countplot(x=col, data=df, color='#2980B9')\n",
    "    \n",
    "    # Annotate the bars with counts\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\n",
    "            f'{int(p.get_height())}', \n",
    "            (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "            ha='center', va='center', \n",
    "            fontsize=11, color='black', \n",
    "            xytext=(0, 5), \n",
    "            textcoords='offset points'\n",
    "        )\n",
    "\n",
    "    plt.title(col, fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Univariate Analysis of Categorical Features', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711cfaf0",
   "metadata": {},
   "source": [
    "## Inference : \n",
    "1. __Gender__: There are more males in the dataset than females.\n",
    "\n",
    "2. __Type of Chest Pain__: There are different types of chest pain in the dataset. The most common type is \"Typical angina,\" but you can see the exact numbers in the bar charts.\n",
    "\n",
    "3. __Fasting Blood Sugar__: Most patients have a fasting blood sugar level below 120 mg/dl, so high blood sugar isn't common in this dataset.\n",
    "\n",
    "4. __Resting Electrocardiographic Results__: There are various outcomes for the resting electrocardiogram. Some types are more common than others, and you can see the details in the plots.\n",
    "\n",
    "5. __Exercise-Induced Angina__: Most patients do not have angina (chest pain) during exercise, suggesting it's not a common symptom here.\n",
    "\n",
    "6. __Slope of the Peak Exercise ST Segment__: The dataset shows different types of slopes for the ST segment during peak exercise. One type might be more common, and you can check the exact numbers in the bar charts.\n",
    "\n",
    "7. __Number of Major Vessels Colored by Fluoroscopy__: Most patients have fewer major vessels colored, with '0' being the most common number.\n",
    "\n",
    "8. __Thalium Stress Test Result__: There are different results from the thalium stress test. One type is more common, but you can see the exact details in the plots.\n",
    "\n",
    "9. __Presence of Heart Disease__: About 54.5% of the patients have heart disease, while 45.5% do not, so the dataset is almost evenly split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f6656",
   "metadata": {},
   "source": [
    "## 6.6) Bivariate Analysis of Categorical Features by Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn style and font scale\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "# Define target variable\n",
    "target_variable = 'target'  # Replace 'target' with your actual target variable name\n",
    "\n",
    "# Create subplots for bivariate analysis\n",
    "plt.figure(figsize=(12, 20))\n",
    "\n",
    "for i, col in enumerate(cate_cols, start=1):\n",
    "    plt.subplot(4, 2, i)\n",
    "    ax = sns.histplot(data=df, x=col, hue=target_variable, multiple='stack', palette='Set1', edgecolor='black')\n",
    "    \n",
    "    # Customize the plot with more aesthetics\n",
    "    ax.set_title(f'{col.capitalize()} Distribution by {target_variable.capitalize()}', fontsize=16, fontweight='bold', pad=10)\n",
    "    #ax.set_xlabel(col.capitalize(), fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Frequency', fontsize=14, fontweight='bold')\n",
    "    #ax.legend(title=target_variable.capitalize(), title_fontsize='13', fontsize='11', loc='upper right')\n",
    "    \n",
    "    # Add grid lines for better readability\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.suptitle('Bivariate Analysis of Categorical Features by Target Variable', fontsize=18, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e374e54",
   "metadata": {},
   "source": [
    "## Inference : \n",
    "1. __Number of Major Vessels__: Most people with heart disease have fewer major vessels showing up in the test. If someone has 0 vessels colored, they are more likely to have heart disease.\n",
    "\n",
    "2. __Chest Pain Type__: Different types of chest pain are linked to heart disease in different ways. Types 1, 2, and 3 are more common in people with heart disease, suggesting that chest pain type can help predict the disease.\n",
    "\n",
    "3. __Exercise-Induced Angina__: People who don’t have chest pain during exercise are more likely to have heart disease compared to those who do have chest pain during exercise. This feature seems important for predicting heart disease.\n",
    "\n",
    "4. __Fasting Blood Sugar__: There isn’t a big difference in heart disease rates between people with high fasting blood sugar and those with normal levels. This suggests that fasting blood sugar might not be very useful for predicting heart disease.\n",
    "\n",
    "5. __Resting Electrocardiographic Results__: The type of resting electrocardiogram result can indicate heart disease. Specifically, type 1 is more common in people with heart disease.\n",
    "\n",
    "6. __Sex__: Women are less likely to have heart disease compared to men, suggesting that gender plays a role in predicting heart disease.\n",
    "\n",
    "7. __Slope of the Peak Exercise ST Segment__: The type 2 slope is more common in people with heart disease, making it a useful indicator for prediction.\n",
    "\n",
    "8. __Thalium Stress Test Result__: The category showing a reversible defect (2) is more common in people with heart disease, highlighting its importance in prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38395d",
   "metadata": {},
   "source": [
    "## 7) Exploring Data Correlations with a Heatmap\n",
    "\n",
    ">**Correlation heatmap is to visually represent the strength and direction of relationships between multiple variables in a dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b3988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of correlations\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='cividis', linewidths=0.5, fmt='.2f', cbar=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0112df4",
   "metadata": {},
   "source": [
    "## Inference :\n",
    ">1. High Positive Correlation on Target: __cp, thalach and slope__\n",
    ">2. High Negative Correlation on Target: __exang, oldpeak, ca and thal__\n",
    ">3. Moderate Negative Correlation on Target: __age and sex__\n",
    ">4. Less Correlation on Target: __tresbps, chol, fbs and restecg__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af211d2",
   "metadata": {},
   "source": [
    "## 8) Fixing Outliers in the dataset\n",
    " >I'm going to use the IQR method to identify outliers in the numerical features.\n",
    " > improve the accuracy of our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67721464",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[cont_cols].quantile(0.25)\n",
    "Q3 = df[cont_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers_count = ((df[cont_cols] < (Q1 - 1.5 * IQR)) | (df[cont_cols] > (Q3 + 1.5 * IQR))).sum()\n",
    "\n",
    "print(\"Outliers Count:\")\n",
    "print(outliers_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c1546",
   "metadata": {},
   "source": [
    "We observed outliers in the continuous variables we analyzed, indicating data points that distinct from others.\n",
    "\n",
    "\n",
    "1. __trestbps__ : 30 outliers\n",
    "2. __chol__ : 16 outliers\n",
    "3. __thalach__ : 4 outlier\n",
    "4. __oldpeak__ : 7 outliers\n",
    "5. __age__ : No outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab1132",
   "metadata": {},
   "source": [
    "## 9) One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6179eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['cp', 'restecg', 'thal'], drop_first=True)\n",
    "df_encoded[['cp_1', 'cp_2', 'cp_3','restecg_1', 'restecg_2', 'thal_1', 'thal_2','thal_3']] = df_encoded[['cp_1', 'cp_2', 'cp_3','restecg_1', 'restecg_2', 'thal_1', 'thal_2','thal_3']].astype('uint8')\n",
    "\n",
    "# Convert the rest of the categorical variables that don't need one-hot encoding to integer data type\n",
    "features_to_convert = ['sex', 'fbs', 'exang', 'slope', 'ca', 'target']\n",
    "for feature in features_to_convert:\n",
    "    df_encoded[feature] = df_encoded[feature].astype(int)\n",
    "\n",
    "df_encoded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef86f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the resulting DataFrame after one-hot encoding\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features (X) and the output labels (y)\n",
    "X = df_encoded.drop('target', axis=1)\n",
    "y = df_encoded['target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv, X_val, y_train_cv, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0282be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Apply Box-Cox transformation to positive-valued features\n",
    "X['oldpeak'], _ = boxcox(X['oldpeak'] + 1)  # Add 1 to handle zeros\n",
    "\n",
    "# Display the first few rows of the transformed dataset\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b9123",
   "metadata": {},
   "source": [
    "## 10) Decision Tree Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37731b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base DT model\n",
    "dt_base = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67cbe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def tune_clf_hyperparameters(clf, param_grid, X_train, y_train, scoring='recall', n_splits=3):\n",
    "    # Shuffle the data to ensure random distribution before cross-validation\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "    \n",
    "    # Create the cross-validation object using KFold\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    clf_grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "    # Fit the GridSearchCV object to the training data\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_hyperparameters = clf_grid.best_params_\n",
    "\n",
    "    # Return the best model and best hyperparameters\n",
    "    return clf_grid.best_estimator_, best_hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for DT\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2,3],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dt, best_dt_hyperparams = tune_clf_hyperparameters(dt_base, param_grid_dt, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DT Optimal Hyperparameters: \\n', best_dt_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441cac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the train data\n",
    "print(classification_report(y_train, best_dt.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the test data\n",
    "print(classification_report(y_test, best_dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Confusion Matrix for Decision Tree Algorithm\n",
    "cm_dt = confusion_matrix(y_test,best_dt.predict(X_test))\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.set_context('notebook',font_scale = 0.9)\n",
    "sns.heatmap(cm_dt,annot=True,fmt='d', cmap=\"Blues\", cbar=False)\n",
    "plt.title('Decision Tree Confusion Matrix');\n",
    "plt.xlabel(\"Predicted_Value\")\n",
    "plt.ylabel(\"True_Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a trained model on test data using various metrics.\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate individual metrics for each class\n",
    "    precision_0 = precision_score(y_test, y_pred, pos_label=0)\n",
    "    precision_1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "    recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1_0 = f1_score(y_test, y_pred, pos_label=0)\n",
    "    f1_1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "   \n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Create a dictionary to store all metrics\n",
    "    metrics = {\n",
    "        \"precision_0\": precision_0,\n",
    "        \"precision_1\": precision_1,\n",
    "        \"recall_0\": recall_0,\n",
    "        \"recall_1\": recall_1,\n",
    "        \"f1_0\": f1_0,\n",
    "        \"f1_1\": f1_1,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "    # Convert dictionary to dataframe\n",
    "    df = pd.DataFrame(metrics, index=[model_name]).round(2)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_evaluation = evaluate_model(best_dt, X_test, y_test, 'DT')\n",
    "dt_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c56e3f",
   "metadata": {},
   "source": [
    "## 11) Logistic Regression Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=10000)\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "param_grid_log_reg = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'solver': ['liblinear', 'saga'],  # Solvers compatible with L1/L2 penalties\n",
    "    'penalty': ['l1', 'l2']  # Penalty terms\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV with recall as the scoring metric\n",
    "grid_search_log_reg = GridSearchCV(log_reg, param_grid_log_reg, cv=5, scoring='recall', n_jobs=-1)\n",
    "grid_search_log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Logistic Regression Best Params:\", grid_search_log_reg.best_params_)\n",
    "print(\"Logistic Regression Best Recall Score:\", grid_search_log_reg.best_score_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = grid_search_log_reg.predict(X_train)\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa784c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = grid_search_log_reg.predict(X_test)\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b72b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Confusion Matrix for Logistic Regression Algorithm\n",
    "cm_lr = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.set_context('notebook',font_scale = 0.9)\n",
    "sns.heatmap(cm_lr,annot=True,fmt='d', cmap=\"Blues\", cbar=False)\n",
    "plt.title('Logistic Regression Confusion Matrix');\n",
    "plt.xlabel(\"Predicted_Value\")\n",
    "plt.ylabel(\"True_Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_evaluation = evaluate_model(grid_search_log_reg, X_test, y_test, 'LR')\n",
    "logistic_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53787c8",
   "metadata": {},
   "source": [
    "## 12) Random Forest Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422460b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 30, 50, 70, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0194df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the tune_clf_hyperparameters function to get the best estimator\n",
    "best_rf, best_rf_hyperparams = tune_clf_hyperparameters(rf_base, param_grid_rf, X_train, y_train)\n",
    "print('RF Optimal Hyperparameters: \\n', best_rf_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26aa071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the train data\n",
    "print(classification_report(y_train, best_rf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the test data\n",
    "print(classification_report(y_test, best_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Confusion Matrix for Random Forest Algorithm\n",
    "cm_rf = confusion_matrix(y_test,best_rf.predict(X_test))\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.set_context('notebook',font_scale = 0.9)\n",
    "sns.heatmap(cm_rf,annot=True,fmt='d', cmap=\"Blues\", cbar=False)\n",
    "plt.title('Random Forest Confusion Matrix');\n",
    "plt.xlabel(\"Predicted_Value\")\n",
    "plt.ylabel(\"True_Value\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_evaluation = evaluate_model(best_rf, X_test, y_test, 'RF')\n",
    "rf_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c094a",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29425e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Apply min-max scaling to numerical columns\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X[cont_cols] = min_max_scaler.fit_transform(X[cont_cols])\n",
    "\n",
    "# Display the first few rows of the scaled dataset\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c12c4",
   "metadata": {},
   "source": [
    "## 13) Logistic Regression Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54274f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_base=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_logistic = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df552eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for hyperparameter tuning with logistic regression\n",
    "best_logistic, best_logistic_hyperparams = tune_clf_hyperparameters(logistic_base, param_grid_logistic, X_train, y_train)\n",
    "\n",
    "# Print the optimal hyperparameters for logistic regression\n",
    "print('Logistic Regression Optimal Hyperparameters: \\n', best_logistic_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b52cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the train data\n",
    "print(classification_report(y_train, best_logistic.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the test data\n",
    "print(classification_report(y_test, best_logistic.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Confusion Matrix for Random Forest Algorithm\n",
    "cm_rf = confusion_matrix(y_test,best_logistic.predict(X_test))\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.set_context('notebook',font_scale = 0.9)\n",
    "sns.heatmap(cm_rf,annot=True,fmt='d', cmap=\"Blues\", cbar=False)\n",
    "plt.title('Logistic Regression Confusion Matrix');\n",
    "plt.xlabel(\"Predicted_Value\")\n",
    "plt.ylabel(\"True_Value\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f16e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_evaluation = evaluate_model(best_logistic, X_test, y_test, 'LR')\n",
    "logistic_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4917059",
   "metadata": {},
   "source": [
    "## 14) Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ddb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm = {\n",
    "    'svm__C': [5],\n",
    "    'svm__kernel': ['linear', 'rbf', 'poly'],\n",
    "#     'svm__gamma': [2],\n",
    "#     'svm__degree': [2,3,4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for hyperparameter tuning\n",
    "best_svm, best_svm_hyperparams = tune_clf_hyperparameters(svm_pipeline, param_grid_svm, X_train, y_train)\n",
    "print('SVM Optimal Hyperparameters: \\n', best_svm_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b913b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the train data\n",
    "print(classification_report(y_train, best_svm.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the test data\n",
    "print(classification_report(y_test, best_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a23ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Confusion Matrix for Support Vector Classifier Algorithm\n",
    "cm_svc = confusion_matrix(y_test, best_svm.predict(X_test))\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.set_context('notebook',font_scale = 0.9)\n",
    "sns.heatmap(cm_svc,annot=True,fmt='d', cmap=\"Blues\", cbar=False)\n",
    "plt.title('Support Vector Confusion Matrix');\n",
    "plt.xlabel(\"Predicted_Value\")\n",
    "plt.ylabel(\"True_Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_evaluation = evaluate_model(best_svm, X_test, y_test, 'SVM')\n",
    "svm_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32045096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes\n",
    "all_evaluations = [dt_evaluation, rf_evaluation, logistic_evaluation, svm_evaluation]\n",
    "results = pd.concat(all_evaluations)\n",
    "\n",
    "# Sort by 'recall_1'\n",
    "results = results.sort_values(by='recall_1', ascending=False).round(2)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e4523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assume 'results' is the DataFrame containing the recall scores for each algorithm\n",
    "# If your DataFrame is named differently or you have specific columns for recall, adjust accordingly\n",
    "\n",
    "# Ensure recall_1 column exists and the DataFrame is sorted by it\n",
    "results_sorted = results.sort_values(by='recall_1', ascending=False)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(12, 7), dpi=70)\n",
    "plt.bar(results_sorted.index, results_sorted['recall_1'], color='darkblue')\n",
    "\n",
    "# Annotate each bar with its recall value\n",
    "for i, (index, row) in enumerate(results_sorted.iterrows()):\n",
    "    plt.text(i, row['recall_1'] + 0.01, f\"{row['recall_1']:.2f}\", ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Recall Values for Different Algorithms\", fontweight='bold', fontsize=22)\n",
    "plt.xlabel('Algorithm', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Recall Value', fontsize=16, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontweight='bold')\n",
    "\n",
    "# Set y-axis limit\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b573d",
   "metadata": {},
   "source": [
    "   The SVM model does a great job at finding people who might have heart disease. It correctly identifies almost all of them, with a recall score of __0.97__ for class 1 (people with heart disease). This is very important in medical situations. The model also makes sure that while it focuses on catching as many cases as possible, it doesn't make too many mistakes by sending false alerts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e110b619",
   "metadata": {},
   "source": [
    "## 15) Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d72ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Function to make a prediction based on user input\n",
    "def make_prediction(features):\n",
    "    return best_rf.predict([features])\n",
    "\n",
    "# Define feature names and create input widgets\n",
    "feature_names = [\"age\", \"sex\", \"trestbps\", \"chol\", \"fbs\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"cp_1\", \"cp_2\", \"cp_3\", \"restecg_1\", \"restecg_2\", \"thal_1\", \"thal_2\", \"thal_3\"]\n",
    "input_widgets = {name: widgets.FloatText(value=0.0, description=f'{name}:') for name in feature_names}\n",
    "\n",
    "# Create a button for making predictions\n",
    "predict_button = widgets.Button(description=\"Predict\")\n",
    "\n",
    "# Output widget to display prediction\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to handle button click event\n",
    "def on_predict_button_click(button):\n",
    "    features = [input_widgets[name].value for name in feature_names]\n",
    "    prediction = make_prediction(features)\n",
    "    \n",
    "    # Display the prediction\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        display(HTML(f\"<b>Prediction:</b> {prediction[0]}\"))\n",
    "\n",
    "# Attach the button click event\n",
    "predict_button.on_click(on_predict_button_click)\n",
    "\n",
    "# Display widgets and output area\n",
    "display(widgets.VBox(list(input_widgets.values()) + [predict_button]), output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe6c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5d37f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
